{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLUQpgdAyJnq"
   },
   "source": [
    "## General instructions\n",
    "\n",
    "Please fill out the answers to the questions below in markdown blocks (for questions) and coding blocks (for coding exercises). \n",
    "\n",
    "For some programming questions, some hints have already been provided for you. Add additional blocks if you need them (e.g. to explain your answers). Try to answer each question succinctly. \n",
    "\n",
    "In the coding exercises, you may use ``pandas``, ``numpy`` and ``scipy`` routines, but **not** scikit-learn (``sklearn``). You may use ``matplotlib`` or ``seaborn`` for plotting.\n",
    "\n",
    "Submit the completed notebook after filling in all the questions and please make sure that the answers are visible without needing to execute each code block (i.e. so the code block has already been executed). When marking the assignment we will not run any code if this has not been done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI statement\n",
    "\n",
    "Please state if you used AI tools in preparing your answers, and if so please explain what you used them for. Note that it is not acceptable to directly paste answers or code generated by AI tools to solve these problems. In cases of doubt we may plan an interview to discuss verbally your understanding of the solutions to the exercises before releasing the final grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Algebra and Data Handling\n",
    "\n",
    "### Task 1.1 (1 point)\n",
    "\n",
    "Suppose that you are given a data matrix (X) that summarises the expenditure of 10 different hospitals across a 6 month period, where the the hospitals are stored one per row and the months are stored one per column. Print out a vector that you can multiply this matrix with to yield the following quantities. In other words, give the vector v that causes the matrix-vector product **X * v** to yield the following:\n",
    " \n",
    "1. The difference in the total expenditure for each hospital between the first three and the last three months\n",
    "2. The total expenditure of the first two months minus the average expenditure for each hospital for the the last four monthmonths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nC0Wd_jWyJnr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.rand(10,6) # dummy data\n",
    "\n",
    "v1 = \n",
    "\n",
    "v2 = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwqxZOEByJns"
   },
   "source": [
    "### Task 1.2 (1 point)\n",
    "\n",
    "Write a short piece of code that uses an eigendecomposition to determine the rank of the following matrix. Check your answer by computing the rank directly using the function np.linalg.matrix_rank():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaa4fBnsyJns"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[ -2., 20., -6.,  7.,  7., 4.],\n",
    "              [ 9., 5., 9.,  7.,  7., 0.],\n",
    "              [ -1., 3., 4.,  -2.,  9., -27.],\n",
    "              [ 8., 11., 2.,  9.,  4., 16.],\n",
    "              [ 4., 19.,  -3.,  8.,  8., 7.],\n",
    "              [ 6., 7.,  7., 10.,  4., 11.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvlxipudyJns"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3 (2 points)\n",
    "\n",
    "Download the data below and perform a basic quality control procedure using basic statistical operations. You can assume that the data contain demographic measures plus some biological features (it does not matter what these are for the purposes of this exercies).\n",
    "\n",
    "Then answer the following  questions: \n",
    "\n",
    "1. Which subject has the most missing data? How many missing features does this subject have?\n",
    "2. Which are the features most likely to contain outliers? How many samples would you remove? Give reasons for your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/predictive-clinical-neuroscience/BigDataCourse/main/data/qc_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4 (1 point)\n",
    "\n",
    "What do we use the Digital Research Environment for?\n",
    "\n",
    "1. Data collection\n",
    "2. Data processing and analysis\n",
    "3. Collaborating on shared data with external parties\n",
    "4. Archiving\n",
    "5. Making data FAIR\n",
    "\n",
    "select all answers that apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIatJnjQyJns"
   },
   "source": [
    "# Part 2: Machine learning and statistics\n",
    "\n",
    "### Task 2.1 (1 point)\n",
    "\n",
    "1. Describe the function of the parameter $\\gamma$ in support vector machines (following the notation given in the lectures). How does it prevent overfitting?\n",
    "2. Linear models have different kinds of parameters. Briefly describe the different functions of the parameters denoted $w$ and $\\theta$ given in the machine learning lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muZv-1VsyJns"
   },
   "source": [
    "### Task 2.2 (1 point)\n",
    "\n",
    "Considering the following scenario: \n",
    "\n",
    "A researcher wants to train a classifier to predict Parkinson's disease and acquires some neuroimaging data to do this. First, the researcher selects the most informative features from the imaging data using a t-test. Next, the researcher trains a classifier on these features using cross-validation and obtains classification accuracy of 75% for discriminating patients from controls. The researcher shows that this is statistically better than chance (50%) using a binomial test. \n",
    "\n",
    "Would you consider this to be a solid workflow? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNy2-Yl6yJnt"
   },
   "source": [
    "### Task 2.3 (1 point)\n",
    "\n",
    "Suppose that you are the data scientist working for clinic that performs biopsies for lung cancer. In this clinic, you know that using a 'gold standard' test, approximately 5% of the samples that are tested come back positive for lung cancer and you test approximately 1000 people per year. You are evaluating a new test that according to the manufacturer has a sensitivity of approximately 80% and a specificity of 95% but is appealing because it is much faster than the gold standard test, meaning that the patients will have their results the same day instead of having to wait a week.\n",
    "\n",
    "First, write a small block of python code to estimate the accuracy, positive and negative predictive value of the test under the scenario above. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KEE2avqyJnt"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSUSAPwyJnt"
   },
   "source": [
    "### Task 2.4 (1 point)\n",
    "\n",
    "Would you switch to the new test? Give reasons for your answer. Can you think of factors that would change your preference? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_M7J4tqyJnt"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpAfhPyVyJnt"
   },
   "source": [
    "### Task 2.5 (1 point)\n",
    "\n",
    "Consider the following scenario: a researcher would like to use a clustering algorithm to find subtypes of asthma. The researcher acquires biomedical data, including: 3 lung function parameters from a breath outflow test, 10 blood-based markers (that you can assume are known to be associated with asthma) and 100 genetic variables (that have each been associated with asthma in at least one study). The researcher trains a K-means algorithm across 2-5 clusters and finds that the 5 cluster solution is the most reproducible (statistically significant at p < 0.01). \n",
    "\n",
    "Please answer the following questions: \n",
    "\n",
    "1. Would you consider this to be acceptable evidence to determine that biological subtypes exist? \n",
    "2. Please briefly outline what addtional validation steps you would recommend to determine whether the clusters can be used to improve prediction of outcomes in asthma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFdbYHzAyJn5"
   },
   "source": [
    "### Task 2.6 (1 point)\n",
    "\n",
    "Matrix decomposition techniques are important ways to reduce dimensionality in big data cohorts. Provide brief answers to the following questions: \n",
    "\n",
    "1. What are the steps needed to perform principal components analysis (PCA) on the basis of an eigendecomposition?\n",
    "2. What is the difference between running linked ICA on multimodal data from concatenating the data and running PCA?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6KSz0ouyJn5"
   },
   "source": [
    "## Part 3: Analysis of Parkinson's disease dataset\n",
    "\n",
    "For this part of the assignment, we will work with electronic measurements of voice characteristics from 42 people with early-stage Parkinson's disease. These participants were included in a six-month trial of a telemonitoring device for remote symptom progression monitoring. The motivation is that Parkinson's disease affects the characteristics of the voice in a way that might be associated with disease progression. See [here](https://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring) for a description of the data. Note that the UPDRS (Unified Parkinson's Disease Rating Scale) is a standard scale for rating the symptoms of Parkinson's disease across different domains.\n",
    "\n",
    "For this assignment, we have split the dataset into two parts, which you can download here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yY2quKQnyJn5"
   },
   "outputs": [],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/predictive-clinical-neuroscience/BigDataCourse/main/data/parkinsons_updrs_dataset1.csv\n",
    "!wget -nc https://raw.githubusercontent.com/predictive-clinical-neuroscience/BigDataCourse/main/data/parkinsons_updrs_dataset2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9dt77USyJn5"
   },
   "source": [
    "### Task 3.0 (1 point, bonus question)\n",
    "Load the data and count the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WPTDxQ_yJn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lcIMnWiyJn5"
   },
   "source": [
    "### Task 3.1 (2 points)\n",
    "\n",
    "Your first task is to perform PCA on the first data matrix (\"parkinsons_updrs_dataset1\"), then:\n",
    "\n",
    "* plot the eigenvalues sorted from largest to smallest\n",
    "* print the number of components you would need to retain 99.9% of the variance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bge-LtvyJn5"
   },
   "source": [
    "### Task 3.2 (1 point)\n",
    "\n",
    "Your next task is to fit a GLM to predict symptom severity ('total_UPDRS') on the basis of age, sex and the 16 biomedical voice measurements using only the first part of the Parkinson dataset. Don't forget to account for the fact that the symptom severity does not have a zero mean. Print out the regression coefficients and make a plot of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_G6z79XyJn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmXw4EEryJn5"
   },
   "source": [
    "### Task 3.3 (1 point)\n",
    "\n",
    "Now, evaluate how accurately this model can predict the true symptom scores. To do this compute the correlation between the true and predicted symptom scores as well as the explained variance score. Print these values. \n",
    "\n",
    "Hint: the explained variance can be computed as $1-var(y-\\hat{y})/var(y)$ where $y$ and $\\hat{y}$ are the true and predicted labels respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thmZRw6tyJn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTGhZxvdyJn5"
   },
   "source": [
    "### Task 3.4 (1 point)\n",
    "\n",
    "Now compute the predictions on the second dataset using the coefficients estimated on the first dataset. Compute and print the correlation and explained variance as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILZJhEdKyJn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-YtJY6OyJn5"
   },
   "source": [
    "### Task 3.5 (1 point)\n",
    "\n",
    "Now, we are going to interpret these results. Please answer the following questions:\n",
    "\n",
    "1. Can you see evidence for overfitting? why or why not?  \n",
    "2. Which do you think might be the most important explanatory variables ? Explain why you think that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhsjbg2xyJn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hTu6r88yJn5"
   },
   "source": [
    "### Task 3.6 (2 points)\n",
    "\n",
    "Now write a piece of code to do PCA on the set of features mentioned in task 3.2 above (i.e. age, sex and the 16 biomedical voice measurements) from the first dataset. \n",
    "\n",
    "Then predict the total UPDRS score for the second dataset on the basis of the first 3 principal components. In order to make sure this is unbiased do this in a way that ensures the second dataset is completely independent (i.e. as if someone else has it). \n",
    "\n",
    "Compute the explained variance and compare with what you have above. In your opinion does using three principal components provide adequate compression for this task? Why or why not?\n",
    "\n",
    "_Hint: you will need to project the data onto the principal components. This can be done efficiently using a matrix operation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
