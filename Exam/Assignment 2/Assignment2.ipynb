{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ShR37Z8reyj"
      },
      "source": [
        "## Task 1.1 Summarize the GWAS results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-WtMrHSsHiu"
      },
      "source": [
        "In this first part of the assignement, we are going to load the summary results from a Genome-Wide Association Study (GWAS) and examine its results. In the second part, we examine the mouse homologous gene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcEHCjJU0yB5"
      },
      "outputs": [],
      "source": [
        "### THE TEXT AND CODE IN THIS FIELD IS PROVIDED TO THE STUDENTS\n",
        "#\n",
        "### Read ALL instructions FIRST before you begin your data analysis\n",
        "#\n",
        "# We are going to examine the GWAS ouput (i.e. summary statistics) of the 2018 GWAS of Major Depression conducted by the PGC.\n",
        "# The data belong to this publication: Nat Genet. 2018 May;50(5):668-681. doi: 10.1038/s41588-018-0090-3. PMID:29700475\n",
        "#\n",
        "# Download this summary statistics file:\n",
        "! wget \"https://www.dropbox.com/scl/fi/yj3m8d2puymhdzufanhs9/MDD2018_ex23andMe.txt?rlkey=4dl6gdi977dyj6neuwjtdf1xv&st=82vc8u0o&dl=0\"  -O MDD_2018_original.tsv\n",
        "\n",
        "# Download the README file:\n",
        "! wget \"https://www.dropbox.com/scl/fi/0buvztu2sl6xa12vwvwyb/pgc-mdd-2018-readme.pdf?rlkey=r6qdropq18mi5rowplhoagcp8&st=v4i71xip&dl=0\" -O MDD_2018_README.pdf\n",
        "\n",
        "# Read the README file before moving to Task 1.1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkXDxly4sM5Y"
      },
      "source": [
        "**Q1.1.** Load the **tab** separated file 'MDD_2025_gwas_data.tsv' into a table and **check the content and the format**. Show your code and explain what you are doing and why. [2 points]\n",
        "\n",
        "Relevant column headers:\n",
        " 1 CHROM: Chromosome;\n",
        " 2\tPOS: Base-pair position (GRCh37);\n",
        " 3\tSNP: SNP Marker ID (rs identifier);\n",
        " 8\tPVAL: P-value;\n",
        "\n",
        "**Q1.2.** How many SNPs were tested?  [1 point]\n",
        "\n",
        "**Q1.3.** Find the **most significant SNP**. What is this top SNP's rs identifier? [1 point]\n",
        "\n",
        "**Q1.4.** Using the NCBI online database, in which gene is SNP rs9479138 located? [0.5 point]\n",
        "\n",
        "**Q1.5.** Looking further in the NCBI database, in which body tissue or organ is this gene most expressed? Provide a link/url showing how you got to this answer. [0.5 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ePU355NsZ7d"
      },
      "source": [
        "## Task 1.2 Microarray database\n",
        "Another gene that has often been associated with Major Depression is **PGBD1**.In the Allen Institute microarray database, search for expression patterns of PGBD1: https://human.brain-map.org/microarray/search.\n",
        "\n",
        "Download the relevant data for PGB1 (first probe, first row). There are two ways to do this:\n",
        "1. Select the top row (probe) and download this data. Upload the data into  Colab by clicking on the 'file' icon on the top left corner.\n",
        "2. Run the code provided below using wget commands (pointing to a dropbox database)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DspeMjifbHbp"
      },
      "outputs": [],
      "source": [
        "#### This is provided to the students! #######\n",
        "#downloading data\n",
        "! wget 'https://www.dropbox.com/scl/fi/th8ykvjnk9rlao0ccp47d/Columns.csv?rlkey=dttm23lamkhugkypb0r5bgaj2&st=1wkbgc7r&dl=0' -O Columns.csv\n",
        "! wget 'https://www.dropbox.com/scl/fi/xs9g0r3egrxi93hhn9pel/Expression.csv?rlkey=jf47vz3ez0mxeascgjdqjn6rc&st=92e3dfew&dl=0' -O Expression.csv\n",
        "! wget 'https://www.dropbox.com/scl/fi/j2cn98z1vu5igppx69ayf/Contents.txt?rlkey=ew526p39wpe78os3x46rzglrg&st=wd6jzr40&dl=0' -O Contents.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-2hdvEEryGO"
      },
      "source": [
        "**Read the \"Contents.txt\" file.**\n",
        "\n",
        "**Load the Expression.csv file and the Columns.csv file in python.**\n",
        "\n",
        "**Q1.6**  Format the data of Expression.csv and Columns.csv so that you have a table with 1 column of PGB1 expression values, next to columns with information of regions and subjects (donors). You should have 1 row per brain structure for each subject. (1 point)\n",
        "\n",
        "**Q1.7** Calculate the mean expression accross participants per brain structure.  In which brain structure does this PGB1 have the highest mean expression? (0.5 point)\n",
        "\n",
        "**Q1.8**   How many missing values are there for the expression of this gene across all brain regions? And for the brain region with the highest expression? (0.5 point)\n",
        "\n",
        "**Q1.9**  Does PGBD1 look consistently highly expressed across subjects in this top brain region? For full points, consider patterns of PGBD1 expression across different subjects and brain regions. Use figures and/or statistics to help you decide. (2 points)\n",
        "\n",
        "**Q1.10**   Looking at a coarser level of analysis, in which (larger) brain structures is PGBD1 most highly expressed? (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPsowrytsu6i"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "--------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzU3COJDxynn"
      },
      "source": [
        "# Task 2: Mouse phenome database\n",
        "\n",
        "For this task, you will download and import some files from the Mouse Phenome Database (MPD, https://phenome.jax.org). This is a database containing a large amount of mouse experimental data, where information on several phenotypes/genotypes can be found.\n",
        "\n",
        "Execute the wget commands to download the following files to the colab session and the pd.read_csv commands to load them into python.\n",
        "\n",
        "Here is a short description of the file contents.\n",
        "\n",
        "- measurements.csv (= Description, units, and other metadata attributes for all phenotype measures (traits) in MPD. One row per measure.)\n",
        "- straininfo.csv (= Strain name, vendor, stock number, web page URL, MPD strain ID, and other attributes for each mouse strain in MPD. One row per strain.)\n",
        "- strainmeans.csv.gz (= Strain averages, SD, SEM, N, CV for all numeric strain survey phenotype measures in MPD.)\n",
        "- animaldatapoints.csv.gz (= Individual mouse readings for all strain survey phenotype measures. One row per animal reading.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYzpBoIrcopb"
      },
      "source": [
        "**Q2.1** How many different mouse strains are listed in the database? (1pt)\n",
        "\n",
        "**Q2.2** Several strains are not included in projects (n_proj is `nan`). How many strains were actually used in projects? (1pt)\n",
        "\n",
        "**Q2.3** Which strain was used in the most projects, give the name and id (1 pt)\n",
        "\n",
        "**Q2.4** Using the measurements and strainmeans file, look up the experiment with measnum = 29508. Give the description of the experiment and the average results for strain C3HeB/FeJ. (**hint:** You should get two values, one for males and one for females) (1 pts)\n",
        "\n",
        "**Q2.5** For the experiment above (29508) take the results from BALB/cByJ mice (strainid = 50) in animaldatapoints and perform a two-tailed two-sample t-test for `males > females`. What are the t-value and the p-value? (2 pts)\n",
        "\n",
        "**Q2.6** Plot a dotplot of the the body weight (measnum = 11201 listed in `measurements`) on the y-axis as a function of strain name on the x axis. Color-code sex. Add sensible title and axis labels. Make the axis legend lisible. (**hint:** strain ID is encoded differently in the tables!!!) (2 pts)\n",
        "\n",
        "**Q2.7** The project  \"Wahlsten1\" (projsym = \"Wahlsten1\" listed in `measurements`) examines anxiety behaviour using two assays (open field test) and elevated plus maze (epm) in 20 strains, and across both sexes. Plot the mean values across strain and sex for measnum =  10831 (percentage of time spent 10 cm from the wall, higher values indicate more anxiety) on the x-axis, and measnum = 10852 (percentage of time spent in open arms vs closed. lower values indicate less anxiety) on the y-axis. Add a regression line to the plot. Add sensible title and axis labels. Make the axis legend lisible. Get a correlation value for the two measurments. (3 pts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "98zGbhAgcopc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-01 23:43:34--  https://phenomedoc.jax.org/MPD_downloads/measurements.csv\n",
            "Herleiden van phenomedoc.jax.org (phenomedoc.jax.org)... 34.49.178.191\n",
            "Verbinding maken met phenomedoc.jax.org (phenomedoc.jax.org)|34.49.178.191|:443... verbonden.\n",
            "HTTP-verzoek is verzonden; wachten op antwoord... 200 OK\n",
            "Lengte: 1541446 (1,5M) [text/csv]\n",
            "Wordt opgeslagen als: ‘measurements.csv’\n",
            "\n",
            "measurements.csv    100%[===================>]   1,47M  --.-KB/s    in 0,1s    \n",
            "\n",
            "2025-12-01 23:43:35 (9,94 MB/s) - '‘measurements.csv’' opgeslagen [1541446/1541446]\n",
            "\n",
            "--2025-12-01 23:43:35--  https://phenomedoc.jax.org/MPD_downloads/straininfo.csv\n",
            "Herleiden van phenomedoc.jax.org (phenomedoc.jax.org)... 34.49.178.191\n",
            "Verbinding maken met phenomedoc.jax.org (phenomedoc.jax.org)|34.49.178.191|:443... verbonden.\n",
            "HTTP-verzoek is verzonden; wachten op antwoord... 200 OK\n",
            "Lengte: 361068 (353K) [text/csv]\n",
            "Wordt opgeslagen als: ‘straininfo.csv’\n",
            "\n",
            "straininfo.csv      100%[===================>] 352,61K  --.-KB/s    in 0,05s   \n",
            "\n",
            "2025-12-01 23:43:35 (7,65 MB/s) - '‘straininfo.csv’' opgeslagen [361068/361068]\n",
            "\n",
            "--2025-12-01 23:43:36--  https://phenomedoc.jax.org/MPD_downloads/strainmeans.csv.gz\n",
            "Herleiden van phenomedoc.jax.org (phenomedoc.jax.org)... 34.49.178.191\n",
            "Verbinding maken met phenomedoc.jax.org (phenomedoc.jax.org)|34.49.178.191|:443... verbonden.\n",
            "HTTP-verzoek is verzonden; wachten op antwoord... 200 OK\n",
            "Lengte: 6603668 (6,3M) [application/gzip]\n",
            "Wordt opgeslagen als: ‘strainmeans.csv.gz’\n",
            "\n",
            "strainmeans.csv.gz  100%[===================>]   6,30M  9,43MB/s    in 0,7s    \n",
            "\n",
            "2025-12-01 23:43:37 (9,43 MB/s) - '‘strainmeans.csv.gz’' opgeslagen [6603668/6603668]\n",
            "\n",
            "--2025-12-01 23:43:37--  https://phenomedoc.jax.org/MPD_downloads/animaldatapoints.csv.gz\n",
            "Herleiden van phenomedoc.jax.org (phenomedoc.jax.org)... 34.49.178.191\n",
            "Verbinding maken met phenomedoc.jax.org (phenomedoc.jax.org)|34.49.178.191|:443... verbonden.\n",
            "HTTP-verzoek is verzonden; wachten op antwoord... 200 OK\n",
            "Lengte: 18872647 (18M) [application/gzip]\n",
            "Wordt opgeslagen als: ‘animaldatapoints.csv.gz’\n",
            "\n",
            "animaldatapoints.cs 100%[===================>]  18,00M  9,33MB/s    in 1,9s    \n",
            "\n",
            "2025-12-01 23:43:39 (9,33 MB/s) - '‘animaldatapoints.csv.gz’' opgeslagen [18872647/18872647]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# code to download the data\n",
        "\n",
        "! wget --no-check-certificate https://phenomedoc.jax.org/MPD_downloads/measurements.csv\n",
        "! wget --no-check-certificate https://phenomedoc.jax.org/MPD_downloads/straininfo.csv\n",
        "! wget --no-check-certificate https://phenomedoc.jax.org/MPD_downloads/strainmeans.csv.gz\n",
        "! wget --no-check-certificate https://phenomedoc.jax.org/MPD_downloads/animaldatapoints.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FOkPUvqWcopc"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../Assignment 2/measurements.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# code to load the data into pandas dataframes\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m measurements = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../Assignment 2/measurements.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m straininfo = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mstraininfo.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m strainmeans = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mstrainmeans.csv.gz\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/BMS85/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/BMS85/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/BMS85/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/BMS85/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/BMS85/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../Assignment 2/measurements.csv'"
          ]
        }
      ],
      "source": [
        "# code to load the data into pandas dataframes\n",
        "import pandas as pd\n",
        "measurements = pd.read_csv('../Assignment 2/measurements.csv')\n",
        "straininfo = pd.read_csv('straininfo.csv')\n",
        "strainmeans = pd.read_csv('strainmeans.csv.gz')\n",
        "animaldatapoints = pd.read_csv('animaldatapoints.csv.gz')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
